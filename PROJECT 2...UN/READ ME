# ğŸ› ï¸ Python Job Scraper - Zimbabwe Job Listings

This project is a simple Python program that collects job ads from [https://vacancymail.co.zw/jobs](https://vacancymail.co.zw/jobs) and saves them into a file you can open with Excel or Google Sheets.

---

## ğŸ“š What it Does

- âœ… Looks for the **10 most recent jobs**
- âœ… Collects these details:
  - Job Title ğŸ§‘â€ğŸ’¼
  - Company ğŸ¢
  - Location ğŸ“
  - Expiry Date â³
  - Job Description ğŸ“
- âœ… Saves all of this into a file called **`scraped_data.csv`**
- âœ… Shows info and problems in the terminal using logs
- âœ… You can also make it run by itself every day if you want

---

## ğŸ–¥ï¸ Requirements

Before using it, make sure you have:

- Python 3.10 or newer installed
- These Python libraries:
  - `requests`
  - `beautifulsoup4`
  - `pandas`
  - `schedule` *(for optional automation)*

### ğŸ§ª To install them:
```bash
pip install requests beautifulsoup4 pandas schedule
ğŸš€ How to Run the Scraper
Download or clone this project

Open the terminal (or PowerShell)

Run this command:

bash
Copy
Edit
python web_scraper.py
After it's done, check the file called scraped_data.csv â€“ that's where your job data will be!

â±ï¸ Optional: Make it Run Every Day
This project can run automatically every day.

If you want that:

Open web_scraper.py

At the bottom you'll see a schedule block

Uncomment it (remove the #) and run the script

You can also use Windows Task Scheduler or cron (Linux/macOS) to run it daily.

ğŸ› Error Handling & Logs
This script:

Prints messages like â€œStarting...â€ or â€œNo jobs foundâ€

If something goes wrong (like no internet), it shows an error message in the terminal

If the website changes how it looks, it will warn you

ğŸ“‚ Files in the Project
File	What it does
web_scraper.py	The main Python code
scraped_data.csv	Output file with the job listings
README.md	This help file
ğŸ¤ Made With Love
This was created as part of a programming crash course to learn about:

Python

Web scraping

Automation

CSV data handling

